{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "intro_text = \"\"\"\n",
    "# ðŸš€ PyArrow Playground\n",
    "### by **Swap**\n",
    "\n",
    "Hey there ðŸ‘‹ â€” welcome to my personal **PyArrow exploration notebook**!\n",
    "This is where Iâ€™m monkeying around, learning, and building a deeper understanding of how\n",
    "**Apache Arrow** handles memory, arrays, tables, and how it fits with libraries like\n",
    "**Pandas**, **Polars**, and **DuckDB**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ What I've Explored until now\n",
    "- ðŸ§± How Arrow stores data in a *columnar, zero-copy* form or way\n",
    "- ðŸ“Š Creation and manipulation of **Arrow Arrays** and **Tables**\n",
    "- âš™ï¸ Used `pyarrow.compute` for fast math and filtering\n",
    "- ðŸ” Converted data between **PyArrow â†” Pandas â†” Polars**\n",
    "- âš¡ Benchmarked Arrowâ€™s performance, out of curiosity\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§° The Toolkit\n",
    "| Library | What Iâ€™m Using It For |\n",
    "|----------|----------------------|\n",
    "| ðŸ **Python 3.13** | The usual suspect |\n",
    "| ðŸ§± **PyArrow** | The main attraction |\n",
    "| ðŸ“Š **Polars / Pandas** | Easy DataFrame comparisons |\n",
    "| ðŸ§® **DuckDB** | Running SQL magic in-memory |\n",
    "| â± **time / numpy** | Tiny performance tests |\n",
    "\n",
    "---\n",
    "\n",
    "### âœï¸ A Few Notes\n",
    "This isnâ€™t a strict tutorial â€” more of a â€œ**Swap experiments and learns Arrow**â€ space.\n",
    "Iâ€™ll be running random tests, trying weird stuff, and breaking things on purpose ðŸ˜…\n",
    "\n",
    "If it looks messy at times, there's gotta be some decent insight which you might figure out.\n",
    "Letâ€™s see what this beast called **PyArrow** can really do ðŸ”¥\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ“… **Started:** October 2025\n",
    "ðŸ‘¨â€ðŸ’» **Author:** *Swap*\n",
    "ðŸ—ï¸ **Notebook Mood:** Curious & de - caffeinated â˜•\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(intro_text))"
   ],
   "id": "ff9423f30b486863"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.477026Z",
     "start_time": "2025-10-26T15:50:53.475243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# In this tab we shall start with the basics\n",
    "# Let us first start by importing the PyArrow\n",
    "import pyarrow as pa\n",
    "print(\"Import of pyarrow was successful\")"
   ],
   "id": "833aa2b528338708",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import of pyarrow was successful\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.499297Z",
     "start_time": "2025-10-26T15:50:53.496946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we will create an array with some values\n",
    "days = pa.array([1,2,3,4,5,6,7], type=pa.int8())\n",
    "# so the first list tells us which values will be there in our list, and the type tells the type of the vector, we must remember at all cost that this a vector list meaning the list cannot have different data types.\n",
    "print(f\"Here is a quick view of the array: {days}\")\n",
    "# So interestingly if we had created the same array with the help of numpy there would not have been commas between the elements, let me show you that in the next cell"
   ],
   "id": "ded3618336d37d61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a quick view of the array: [\n",
      "  1,\n",
      "  2,\n",
      "  3,\n",
      "  4,\n",
      "  5,\n",
      "  6,\n",
      "  7\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.514248Z",
     "start_time": "2025-10-26T15:50:53.512172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "days_with_numpy_1 = np.arange(7)\n",
    "days_with_numpy_2 = np.array([1,2,3,4,5,6,7])\n",
    "print(f\"So here is the difference between the prior one and this one: {days_with_numpy_1} vs {days_with_numpy_2} and finally the previous one which we had created with pyarrow: {days}\")\n",
    "\n",
    "# See in numpy there are no commas\n"
   ],
   "id": "d9793048f5e96cf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So here is the difference between the prior one and this one: [0 1 2 3 4 5 6] vs [1 2 3 4 5 6 7] and finally the previous one which we had created with pyarrow: [\n",
      "  1,\n",
      "  2,\n",
      "  3,\n",
      "  4,\n",
      "  5,\n",
      "  6,\n",
      "  7\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### `PyArrow`  arrays are not  â€œPythonicâ€  containers â€”\n",
    "##### theyâ€™re `immutable`, `low-level`, `columnar memory buffers`, not dynamic numeric objects like `NumPy` arrays or Pandas Series."
   ],
   "id": "5497354ef9a2b6c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.523421Z",
     "start_time": "2025-10-26T15:50:53.521492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# in this cell lets see how the vectors handle the multiplication\n",
    "# print(f\"Here goes pyarrow: {(items * 5) for items in days}\")\n",
    "\n",
    "# Ah-Oh!! we could not do that because unlike a math engine as numpy PyArrow is a memory format. it Gives us Efficient Storage, Serialization similar to Pandas, Spark, Polars, these arrays are immutable, we cannot simply change them like that\n",
    "\n",
    "print(f\"Here goes numpy: {days_with_numpy_2 * 5}\")"
   ],
   "id": "17d6d58132123bd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here goes numpy: [ 5 10 15 20 25 30 35]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.540653Z",
     "start_time": "2025-10-26T15:50:53.538473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's continue out hunt for PyArrow\n",
    "days_2 = pa.array([4,6,2,7,4,9,1], type=pa.int8())\n",
    "months = pa.array([1,3,5,7,9,11,13], type=pa.int8())\n",
    "years = pa.array([1990, 2000, 1995, 2000, 1995, 1990, 2010], type = pa.int16())\n",
    "\n",
    "birthdays_table = pa.table([years,days_2,months], names=['years','days','months'])\n",
    "\n",
    "print(f\" Here is how the table would look like: \"\n",
    "      f\"{birthdays_table}\")"
   ],
   "id": "888563238210a8de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is how the table would look like: pyarrow.Table\n",
      "years: int16\n",
      "days: int8\n",
      "months: int8\n",
      "----\n",
      "years: [[1990,2000,1995,2000,1995,1990,2010]]\n",
      "days: [[4,6,2,7,4,9,1]]\n",
      "months: [[1,3,5,7,9,11,13]]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.569039Z",
     "start_time": "2025-10-26T15:50:53.566700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This is just for practice purposes\n",
    "power_level = pa.array(['S+','A+','SS','B','C+','F'], type = pa.string())\n",
    "names = pa.array(['Swap','Donald','Shreya','Ria','Henry','Derek'])\n",
    "age = pa.array([26,26,21,28,31,39])\n",
    "\n",
    "wrap_up_table = pa.table([names,age,power_level],names=['Names','Age','Power'])\n",
    "\n",
    "print(\" *** This is how the table would look like *** \")\n",
    "\n",
    "print(wrap_up_table)"
   ],
   "id": "12a88ac3f6ab341b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** This is how the table would look like *** \n",
      "pyarrow.Table\n",
      "Names: string\n",
      "Age: int64\n",
      "Power: string\n",
      "----\n",
      "Names: [[\"Swap\",\"Donald\",\"Shreya\",\"Ria\",\"Henry\",\"Derek\"]]\n",
      "Age: [[26,26,21,28,31,39]]\n",
      "Power: [[\"S+\",\"A+\",\"SS\",\"B\",\"C+\",\"F\"]]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Performing `Computations`\n",
    "Finally lets take a look at some of PyArrow's computational power"
   ],
   "id": "f0ddf1f49486ed0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.591314Z",
     "start_time": "2025-10-26T15:50:53.588806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyarrow.compute as pc\n",
    "\n",
    "print(pc.value_counts(birthdays_table['years']))\n",
    "print(\"take a closer look at how the response has been for the command above\")"
   ],
   "id": "815f5abff3606eea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- is_valid: all not null\n",
      "-- child 0 type: int16\n",
      "  [\n",
      "    1990,\n",
      "    2000,\n",
      "    1995,\n",
      "    2010\n",
      "  ]\n",
      "-- child 1 type: int64\n",
      "  [\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    1\n",
      "  ]\n",
      "take a closer look at how the response has been for the command above\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.611004Z",
     "start_time": "2025-10-26T15:50:53.609031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's do the same for the one table that we created for practice purposes\n",
    "\n",
    "print(pc.value_counts(wrap_up_table['Power']))"
   ],
   "id": "abf68da59ad7be7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- is_valid: all not null\n",
      "-- child 0 type: string\n",
      "  [\n",
      "    \"S+\",\n",
      "    \"A+\",\n",
      "    \"SS\",\n",
      "    \"B\",\n",
      "    \"C+\",\n",
      "    \"F\"\n",
      "  ]\n",
      "-- child 1 type: int64\n",
      "  [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#####  Let us now understand what's up with this\n",
    "\n",
    "`Child 1`\n",
    " and\n",
    " `Child 0` thing"
   ],
   "id": "601b4a7ef5b5b977"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Letâ€™s try to figure out whatâ€™s happening behind the scenes ðŸ‘‡\n",
    "\n",
    "## ðŸ§© What We are Seeing is:\n",
    "\n",
    "This output represents a **dictionary-encoded array** in `Apache Arrow`.\n",
    "\n",
    "| Child | Description | Example Type |\n",
    "|--------|--------------|---------------|\n",
    "| **child 0** | Stores the **unique dictionary values** (actual strings) | `string` |\n",
    "| **child 1** | Stores the **integer codes** that reference the dictionary values | `int64` |\n",
    "\n",
    "So, in essence:\n",
    "\n",
    "- **child 0** â†’ `[\"S+\", \"A+\", \"SS\", \"B\", \"C+\", \"F\"]`\n",
    "- **child 1** â†’ `[0, 1, 2, 3, 4, 5]`\n",
    "\n",
    "This encoding allows Arrow to store gigantic string columns **much more efficiently** by avoiding repetition.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Why Dictionary Encoding Exists\n",
    "\n",
    "Dictionary encoding (also called *categorical encoding*) saves memory by:\n",
    "\n",
    "- Storing **each `unique string` only once**.\n",
    "- Replacing `repeated strings` with **integer references** (small but fixed-size).\n",
    "- While keeping the mapping `consistent` and `reversible`.\n",
    "\n",
    "This makes operations like joins, filters, and aggregations faster while reducing memory usage.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ¤” Why Does `child 1` Show All `1`s?\n",
    "\n",
    "You might think that if we reverse the 1 to get its reference string value it might confuse Arrow  but wait:\n",
    "\n",
    "- PyArrow **infers types automatically** and compresses them internally.\n",
    "- The console output shows a **simplified or truncated** internal structure.\n",
    "- Itâ€™s a *visual artifact* â€” the `actual mapping` in memory is still correct.\n",
    "\n",
    "Even though `child 1` looks like `[1, 1, 1, 1, 1, 1]`, the Arrow memory engine correctly maps all values to their corresponding dictionary entries internally.\n",
    "\n",
    "Arrow doesnâ€™t get confused â€” itâ€™s just showing a **debug view**, not the full memory layout.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Verifying Actual Values\n",
    "\n",
    "You can always inspect your data safely using `.to_pylist()`:\n",
    "\n",
    "```python\n",
    "import pyarrow as pa\n",
    "\n",
    "arr = pa.array([\"S+\", \"A+\", \"SS\", \"B\", \"C+\", \"F\"])\n",
    "print(arr.to_pylist())"
   ],
   "id": "76755d4f815a1b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.635810Z",
     "start_time": "2025-10-26T15:50:53.633921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's hit it to see as well if it works or not\n",
    "print(power_level.to_pylist())\n",
    "# See pretty cool right ? Yes.\n"
   ],
   "id": "64ebf598017cedf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S+', 'A+', 'SS', 'B', 'C+', 'F']\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#####  Now we could do the `dictionary encoding` manualy\n",
    "\n",
    "- Here's how we would do it -\n"
   ],
   "id": "aecd1c0e496b7bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.666150Z",
     "start_time": "2025-10-26T15:50:53.664041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indices = pa.array([0,1,2,3,4])\n",
    "dictionary = pa.array(['Sussy','Pisi','Galium','Radium','Tortilla'])\n",
    "\n",
    "dict_array = pa.DictionaryArray.from_arrays(indices,dictionary)\n",
    "\n",
    "print(dict_array)\n",
    "# See ?"
   ],
   "id": "fa7c7d246bb35044",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- dictionary:\n",
      "  [\n",
      "    \"Sussy\",\n",
      "    \"Pisi\",\n",
      "    \"Galium\",\n",
      "    \"Radium\",\n",
      "    \"Tortilla\"\n",
      "  ]\n",
      "-- indices:\n",
      "  [\n",
      "    0,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    4\n",
      "  ]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T01:05:29.278550Z",
     "start_time": "2025-10-24T01:05:29.276932Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "\n",
    "##### So intersting fact - if we want to disable\n",
    "##### Dictionary encoding and store plain\n",
    "##### Strings instead  we can use after `pa.array([...], pa.type= string())`"
   ],
   "id": "ba18437c587d848c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T01:05:29.425759Z",
     "start_time": "2025-10-24T01:05:29.424503Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "##### `Insights`\n",
    "\n",
    "- child 0 - Unique dictionary values\n",
    "- child 1 -  Integer codes referencing dictionary values\n",
    "- Why all 1s? - A simplified debug view - not actual data confusion\n",
    "- By using type=pa.string() at the end, it basically disables encoding\n"
   ],
   "id": "fb88aa79e3faa559"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Working with large data\n",
    "\n",
    "`Arrow` also provides the `pyarrow.dataset` API to work with large data, which will handle for you partitioning of your data in smaller chunks"
   ],
   "id": "11124dfd3b176839"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.697675Z",
     "start_time": "2025-10-26T15:50:53.696212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We shall now try to save our table into an actual parquet file\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "# ds.write_dataset(birthdays_table, \"birthday_details\", format='parquet',\n",
    "#                  partitioning=ds.partitioning(pa.schema([birthdays_table.schema.field(\"years\")])))\n",
    "#\n",
    "# print(\"Saving/ Updation completed\")\n",
    "# We have done it once no need to do it again."
   ],
   "id": "d5d45b8e6805314d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.730374Z",
     "start_time": "2025-10-26T15:50:53.717800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let us now load the partitioned dataset\n",
    "birthdays_dataset = ds.dataset(\"birthday_details\", format='parquet', partitioning=['years'])\n",
    "\n",
    "print(birthdays_dataset.files)"
   ],
   "id": "bb40ef7aae6e04b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['birthday_details/1990/part-0.parquet', 'birthday_details/1995/part-0.parquet', 'birthday_details/2000/part-0.parquet', 'birthday_details/2010/part-0.parquet']\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.746959Z",
     "start_time": "2025-10-26T15:50:53.745339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Previous out-put sort or resembles this:\n",
    "#birthday_details/\n",
    "#â”œâ”€â”€ 1990/\n",
    "#â”‚   â””â”€â”€ part-0.parquet\n",
    "#â”œâ”€â”€ 1995/\n",
    "#â”‚   â””â”€â”€ part-0.parquet\n",
    "#â”œâ”€â”€ 2000/\n",
    "#â”‚   â””â”€â”€ part-0.parquet\n",
    "#â””â”€â”€ 2010/\n",
    " #   â””â”€â”€ part-0.\n",
    "\n",
    " # Each subfolder (e.g. 1990/, 1995/) corresponds to one unique value of the partition key,\n",
    "# which in this case is years."
   ],
   "id": "40f412b97b1a1fab",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T01:39:43.292470Z",
     "start_time": "2025-10-24T01:39:43.291220Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "##### `How the data is Stored`\n",
    "Folder ------- File ------- Data Example\n",
    "\n",
    "`1990/` -----> `part-0.parquet` ----> rows where `years = 1990`\n",
    "\n",
    "\n",
    "##### And So forth"
   ],
   "id": "e7bf6f96c9c4831b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.766472Z",
     "start_time": "2025-10-26T15:50:53.758025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If we did something like this -\n",
    "table  = birthdays_dataset.to_table()\n",
    "print(table) # This gives us back everything"
   ],
   "id": "c75cdd74b2d55fd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "days: int8\n",
      "months: int8\n",
      "years: int32\n",
      "----\n",
      "days: [[4,9],[2,4],[6,7],[1]]\n",
      "months: [[1,11],[5,9],[3,7],[13]]\n",
      "years: [[1990,1990],[1995,1995],[2000,2000],[2010]]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.775177Z",
     "start_time": "2025-10-26T15:50:53.771755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Or, we could load a single partition efficiently (Arrow will read only one folder)\n",
    "\n",
    "table_1995 = birthdays_dataset.to_table(filter = pc.field('years') == 1995)\n",
    "print(table_1995) # see? this is the magic no need to worry about the whole thing, I mean we could have a data set with 10 billion rows, it would be insanely inconvenient to tackle that much at once"
   ],
   "id": "aaccb7765f7ef7fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "days: int8\n",
      "months: int8\n",
      "years: int32\n",
      "----\n",
      "days: [[2,4]]\n",
      "months: [[5,9]]\n",
      "years: [[1995,1995]]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.782763Z",
     "start_time": "2025-10-26T15:50:53.781420Z"
    }
   },
   "cell_type": "markdown",
   "source": "## **Data Types and In-Memory Data Model**",
   "id": "d979e631ec67e499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.804788Z",
     "start_time": "2025-10-26T15:50:53.803550Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "- `pyarrow.DataType`, which descibes the type of an array and also govern how its values are interpreted.\n",
    "\n",
    "- `pyarrow.Schema`, which describe a named collection of types. These can be thought of as the column types in a table-like object.\n",
    "\n",
    "- `pyarrow.Array`,(instances) which are atomic, contiguous columnar data structures composed from Arrow Buffer objects.\n",
    "\n",
    "- `pyarrow.RecordBatch`, which are a collection of Array objects with a particular Schema\n",
    "\n",
    "- `pyarrow.Table`, a logical table data structure in which each column consists of one or more pyarrow.Array objects of the same type.\n"
   ],
   "id": "bec506342c94af90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.808863Z",
     "start_time": "2025-10-26T15:50:53.807745Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## **Type Metadata**\n",
    "\n",
    "Apache Arrow defines language agnostic column-oriented data structures for array data.\n",
    "\n",
    "##### The meaning of all these are -\n",
    "\n",
    "- `Language-agnostic` : not tied to any single programming language, meaning we can use Python, R, C++, JAVA, Rust, Go, etc. All thess language share a common in-memory format, so we could pass data between them without conversion.\n",
    "\n",
    "- `Column-oriented` : data structures: This means that Arrow stores data column-by-column, not row-by-row (like traditional Python lists or C arrays). See example prior to this cell.\n",
    "\n",
    "- `For array data : Arrow is optimized for array-like data â€” that is, tables, vectors, and columns with one data type (integers, floats, strings, etc.).\n",
    "\n",
    "Each column in Arrow is essentially a high-performance array that supports:\n",
    "\tâ€¢\tZero-copy slicing\n",
    "\tâ€¢\tSIMD acceleration (fast CPU vector operations)\n",
    "\tâ€¢\tMemory alignment for speed\n",
    "\n",
    "So you can think of each column as a NumPy-like array but shared across languages\n",
    "\n",
    "#### So we can think of each column as  -- `NumPy-like array`--  but shared across languages."
   ],
   "id": "11ae66da58948acb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:29:03.269657Z",
     "start_time": "2025-10-26T21:29:03.267561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t1 = pa.int32()\n",
    "\n",
    "t2 = pa.string()\n",
    "\n",
    "t3 = pa.binary()\n",
    "\n",
    "t4 = pa.binary(10)\n",
    "\n",
    "t5 = pa.timestamp('ms')\n",
    "\n",
    "t6 = pa.list_(t1)\n",
    "\n",
    "print(t1,\"\",t2,\"\",t3,\"\",t4,\"\",t5,\"\",t6)\n",
    "\n",
    "# Here is a quick view of the different data-types (Not all of them)"
   ],
   "id": "8dc403c1ef5ce74b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32  string  binary  fixed_size_binary[10]  timestamp[ms]  list<item: int32>\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:29:59.139411Z",
     "start_time": "2025-10-26T21:29:59.137286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fields = [\n",
    "    pa.field('s0', t1),\n",
    "    pa.field('s1', t2),\n",
    "    pa.field('s2', t4),\n",
    "    pa.field('s3', t6),\n",
    "]\n",
    "\n",
    "t7 = pa.struct(fields)\n",
    "print(t7)"
   ],
   "id": "a247d6de4ac9775",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct<s0: int32, s1: string, s2: fixed_size_binary[10], s3: list<item: int32>>\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.819293Z",
     "start_time": "2025-10-26T15:50:53.818063Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "631f8b5b08480d31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.822852Z",
     "start_time": "2025-10-26T15:50:53.821655Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c1ee39b57d5027b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.826450Z",
     "start_time": "2025-10-26T15:50:53.825428Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9e969d0f833400b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.830265Z",
     "start_time": "2025-10-26T15:50:53.829054Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "45e2a03d5544be97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.834127Z",
     "start_time": "2025-10-26T15:50:53.832917Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "527eeb529989c49d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:53.837140Z",
     "start_time": "2025-10-26T15:50:53.835983Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dbe265c840a81c25",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
